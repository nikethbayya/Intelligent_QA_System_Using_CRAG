{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LsDh1K3raTHM"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing the required dependencies"
      ],
      "metadata": {
        "id": "9ZAmY3KUT6lK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1byiYdYeK9zO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "26275820-6bf5-4f39-eefc-e63b93a39080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.0/91.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.2/33.2 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.7/418.7 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# installing dependencies (in quiet mode)\n",
        "!pip install langchain_community tiktoken langchain-openai lancedb langchain langchainhub langgraph tavily-python sentence-transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import LanceDB\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "import lancedb\n",
        "from typing import Dict, TypedDict\n",
        "from langchain_core.messages import BaseMessage\n",
        "import json\n",
        "import operator\n",
        "from typing import Annotated, Sequence, TypedDict\n",
        "from langchain import hub\n",
        "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import Document\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.messages import BaseMessage, FunctionMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
        "import pprint\n",
        "from langgraph.graph import END, StateGraph"
      ],
      "metadata": {
        "id": "l32DHqdJadLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30a1434c-3777-4cc1-93f9-803516f2233b",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = \"Enter Tavily API Key\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Enter OpenAi API Key\""
      ],
      "metadata": {
        "id": "CShwo10RZwtG",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Retriever"
      ],
      "metadata": {
        "id": "5OMKwNXFhQ30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of URLs pointing to Jay Alammar's articles on Transformers, BERT, and retrieval using transformers.\n",
        "urls = [\n",
        "    \"https://link.springer.com/article/10.1007/s42979-021-00592-x\",\n",
        "]\n",
        "\n",
        "# For each URL, create a WebBaseLoader instance and load the content.\n",
        "# This returns a list of documents for each URL.\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "\n",
        "# Since each element in 'docs' is itself a list (if the loader splits the page into multiple parts),\n",
        "# we flatten the list of lists into a single list containing all document parts.\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "# Document Chunking:\n",
        "# Initialize a text splitter that uses a TikToken encoder. The splitter is configured to:\n",
        "# - Create chunks with a maximum of 250 characters.\n",
        "# - Have no overlap between consecutive chunks.\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=250,  # Maximum characters per chunk\n",
        "    chunk_overlap=0  # No overlap between chunks\n",
        ")\n",
        "\n",
        "# Split the documents into smaller chunks. This helps when processing long documents,\n",
        "# as many downstream models (like language models) have input length limitations.\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n"
      ],
      "metadata": {
        "id": "zAfB-q9caSvm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lanceDBConnection(embed):\n",
        "    # Connect to a LanceDB database located at the specified path\n",
        "    db = lancedb.connect(\"/tmp/lancedb\")\n",
        "\n",
        "    # Method to initialze a LanceDB database\n",
        "    # Create a table named \"crag_demo\" in the database.\n",
        "    # The table is created with initial data: a dictionary containing two keys:\n",
        "    # - \"vector\": computed by embedding the string \"Hello World\" using the embed object\n",
        "    # - \"text\": the actual string \"Hello World\"\n",
        "    # The mode \"overwrite\" ensures that if a table with the same name exists, it will be replaced.\n",
        "    table = db.create_table(\n",
        "        \"crag_demo\",\n",
        "        data=[{\"vector\": embed.embed_query(\"Hello World\"), \"text\": \"Hello World\"}],\n",
        "        mode=\"overwrite\",\n",
        "    )\n",
        "\n",
        "    # Return the created table for further use\n",
        "    return db\n"
      ],
      "metadata": {
        "id": "x48owa9maYgg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the embedding model (in this case, using OpenAI's embeddings).\n",
        "# This object converts text into vector representations.\n",
        "embedder = OpenAIEmbeddings()\n",
        "\n",
        "# Initialize the LanceDB database by calling the custom connection function.\n",
        "# This creates a table and sets up the connection using the embedder.\n",
        "table = lanceDBConnection(embedder)\n",
        "\n",
        "# Create a vector store using LanceDB from the pre-split documents.\n",
        "# - documents: the list of document chunks (doc_splits) created earlier.\n",
        "# - embedding: the embedder object that will convert each chunk into a vector.\n",
        "# - connection: the LanceDB table (or connection) established above.\n",
        "vectorstore = LanceDB.from_documents(\n",
        "    documents=doc_splits,\n",
        "    embedding=embedder,\n",
        "    connection=table,\n",
        ")\n",
        "\n",
        "# Convert the vector store into a retriever.\n",
        "# This retriever can now be used to perform similarity searches over the stored document embeddings.\n",
        "retriever = vectorstore.as_retriever()\n"
      ],
      "metadata": {
        "id": "MDTXPYTCaYiz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Langraph"
      ],
      "metadata": {
        "id": "nOP0lEGPhl3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The GraphState class is defined using TypedDict,\n",
        "#which specifies that the keys attribute must be a dictionary where each key is a string and the corresponding value can be of any type.\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        keys: A dictionary where each key is a string.\n",
        "    \"\"\"\n",
        "\n",
        "    keys: Dict[str, any]"
      ],
      "metadata": {
        "id": "OKK13vYjaYlJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(state):\n",
        "    \"\"\"\n",
        "    Helper function for retrieving documents.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state. It is expected to be a dictionary with a nested \"keys\" dictionary.\n",
        "                      This \"keys\" dictionary should already contain a \"question\" key, representing the query text.\n",
        "\n",
        "    Returns:\n",
        "        dict: A new state where the \"keys\" dictionary is updated to include:\n",
        "              - \"question\": The original query text.\n",
        "              - \"documents\": The documents that are relevant to that query, as returned by the retriever.\n",
        "    \"\"\"\n",
        "    # Print a header message to indicate that the retrieval process is starting.\n",
        "    # The asterisks provide a clear visual marker in the console output.\n",
        "    print(\"*\" * 5, \" RETRIEVE \", \"*\" * 5)\n",
        "\n",
        "    # Extract the inner dictionary stored under the \"keys\" key from the state.\n",
        "    # This inner dictionary holds our state information such as the question.\n",
        "    state_dict = state[\"keys\"]\n",
        "\n",
        "    # Retrieve the question from the state. This \"question\" is the user's query text that we want to process.\n",
        "    question = state_dict[\"question\"]\n",
        "\n",
        "    # Use the retriever to fetch documents relevant to the question.\n",
        "    # The retriever (assumed to be set up elsewhere in the code) searches for documents whose content semantically matches the question.\n",
        "    documents = retriever.get_relevant_documents(question)\n",
        "\n",
        "    # Create and return a new state dictionary.\n",
        "    # Here we package the original question along with the retrieved documents back into a dictionary under the \"keys\" key.\n",
        "    # This updated state can then be passed along to subsequent functions or steps in a processing pipeline.\n",
        "    return {\"keys\": {\"documents\": documents, \"question\": question}}\n"
      ],
      "metadata": {
        "id": "-uar_yt2aYnh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(state):\n",
        "    \"\"\"\n",
        "    Helper function for generating answers\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state, expected to contain a \"keys\" dictionary\n",
        "                      with a \"question\" key and a \"documents\" key (retrieved earlier).\n",
        "\n",
        "    Returns:\n",
        "        dict: A new state where the \"keys\" dictionary is updated to include the generated answer.\n",
        "              The updated state contains the original \"question\", \"documents\", and a new \"generation\" key.\n",
        "    \"\"\"\n",
        "    # Print a visual marker to indicate that the generation process has started.\n",
        "    print(\"*\" * 5, \" GENERATE \", \"*\" * 5)\n",
        "\n",
        "    # Extract the inner state dictionary from the overall state.\n",
        "    state_dict = state[\"keys\"]\n",
        "\n",
        "    # Retrieve the question and documents from the state.\n",
        "    question = state_dict[\"question\"]\n",
        "    documents = state_dict[\"documents\"]\n",
        "\n",
        "    # Retrieve a prompt template from a hub. Here, \"rlm/rag-prompt\" likely represents a template\n",
        "    # used to combine the context (documents) with the question in a format that the LLM expects.\n",
        "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "    # Initialize the language model (LLM) using ChatOpenAI.\n",
        "    # - model_name: Specifies the particular model version (here, a preview version of GPT-4).\n",
        "    # - temperature: Set to 0 for deterministic outputs.\n",
        "    # - streaming: Set to True to allow the LLM to return outputs as they are generated.\n",
        "    # llm = ChatOpenAI(model_name=\"gpt-4-0125-preview\", temperature=0, streaming=True)\n",
        "    llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, streaming=True)\n",
        "\n",
        "    # Define a nested helper function for formatting retrieved documents.\n",
        "    # This function concatenates the 'page_content' of each document in the list, separated by two newlines.\n",
        "    # Note: In the current code snippet, this function is defined but not explicitly used.\n",
        "    def format_docs(docs):\n",
        "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "    # Construct the RAG (Retrieval-Augmented Generation) chain.\n",
        "    # The pipeline is created by chaining together:\n",
        "    # 1. The prompt (template)\n",
        "    # 2. The language model (LLM)\n",
        "    # 3. A string output parser (StrOutputParser) that likely cleans or formats the LLM output.\n",
        "    # The \"|\" operator is used here to create a pipeline where the output of one component\n",
        "    # feeds into the next.\n",
        "    rag_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "    # Invoke the RAG chain with a dictionary containing:\n",
        "    # - \"context\": The retrieved documents which provide supporting information.\n",
        "    # - \"question\": The original query that needs to be answered.\n",
        "    # The chain processes this input, applies the prompt, passes it to the LLM, and finally parses the output.\n",
        "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
        "\n",
        "    # Return a new state with the same \"question\" and \"documents\", and add the \"generation\" key\n",
        "    # which holds the output from the LLM (the final answer).\n",
        "    return {\n",
        "        \"keys\": {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
        "    }\n"
      ],
      "metadata": {
        "id": "LtfI5vS6aYpm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grade_documents(state):\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state, expected to have a \"keys\" dictionary\n",
        "                      containing at least \"question\" and \"documents\".\n",
        "\n",
        "    Returns:\n",
        "        dict: A new state where the \"keys\" dictionary is updated with:\n",
        "              - \"documents\": Only the documents deemed relevant.\n",
        "              - \"question\": The original question.\n",
        "              - \"run_web_search\": A flag indicating whether to perform a web search.\n",
        "    \"\"\"\n",
        "    # Print a header message to indicate that the relevance check is starting.\n",
        "    print(\"*\" * 5, \" DOCS RELEVANCE CHECK\", \"*\" * 5)\n",
        "\n",
        "    # Extract the inner dictionary from the overall state.\n",
        "    state_dict = state[\"keys\"]\n",
        "\n",
        "    # Retrieve the question (user query) and the list of retrieved documents.\n",
        "    question = state_dict[\"question\"]\n",
        "    documents = state_dict[\"documents\"]\n",
        "\n",
        "    # Define a data model using Pydantic's BaseModel to represent the relevance grade.\n",
        "    # This model expects a single field, binary_score, which should be either 'yes' or 'no'.\n",
        "    class grade(BaseModel):\n",
        "        \"\"\"Binary score for relevance check.\"\"\"\n",
        "        binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
        "\n",
        "    # Initialize a language model (LLM) with deterministic behavior.\n",
        "    # The model used here is a GPT-4 preview, with streaming enabled for real-time output.\n",
        "    # model = ChatOpenAI(temperature=0, model=\"gpt-4-0125-preview\", streaming=True)\n",
        "    model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", streaming=True)\n",
        "\n",
        "    # Convert the Pydantic data model into an OpenAI tool.\n",
        "    # This allows the LLM to interact with our defined function schema.\n",
        "    grade_tool_oai = convert_to_openai_tool(grade)\n",
        "\n",
        "    # Bind the LLM with the tool, enforcing that the tool is used during the invocation.\n",
        "    # This means that the LLM will call a function named \"grade\" when processing the prompt.\n",
        "    llm_with_tool = model.bind(\n",
        "        tools=[convert_to_openai_tool(grade_tool_oai)],\n",
        "        tool_choice={\"type\": \"function\", \"function\": {\"name\": \"grade\"}},\n",
        "    )\n",
        "\n",
        "    # Create a parser that uses the Pydantic model to parse the LLM's output.\n",
        "    # It will convert the raw output from the LLM into a structured format based on our grade model.\n",
        "    parser_tool = PydanticToolsParser(tools=[grade])\n",
        "\n",
        "    # Define the prompt template for the grading task.\n",
        "    # The prompt instructs the LLM to assess whether the given document (context) is relevant\n",
        "    # to the provided user question. The LLM should return a binary score: 'yes' or 'no'.\n",
        "    prompt = PromptTemplate(\n",
        "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
        "        Here is the retrieved document: \\n\\n {context} \\n\\n\n",
        "        Here is the user question: {question} \\n\n",
        "        If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
        "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\",\n",
        "        input_variables=[\"context\", \"question\"],\n",
        "    )\n",
        "\n",
        "    # Create the RAG (Retrieval-Augmented Generation) chain by chaining together:\n",
        "    # 1. The prompt to format the input.\n",
        "    # 2. The LLM with the tool bound for invoking the grading function.\n",
        "    # 3. The parser to convert the LLM output into our structured grade model.\n",
        "    chain = prompt | llm_with_tool | parser_tool\n",
        "\n",
        "    # Initialize a list to hold documents that are considered relevant.\n",
        "    filtered_docs = []\n",
        "\n",
        "    # Initialize a flag for web search. Default is \"No\", meaning no additional web search is needed.\n",
        "    search = \"No\"\n",
        "\n",
        "    # Loop through each retrieved document.\n",
        "    for d in documents:\n",
        "        # Invoke the chain for each document with the document's content and the question.\n",
        "        # The chain processes the prompt, gets a response from the LLM, and then parses the output.\n",
        "        score = chain.invoke({\"question\": question, \"context\": d.page_content})\n",
        "\n",
        "        # Extract the binary score from the parsed result.\n",
        "        grade_result = score[0].binary_score\n",
        "\n",
        "        # If the document is graded as relevant ('yes'), add it to the filtered list.\n",
        "        if grade_result == \"yes\":\n",
        "            print(\"*\" * 5, \" RATED DOCUMENT: RELEVANT\", \"*\" * 5)\n",
        "            filtered_docs.append(d)\n",
        "        else:\n",
        "            # If not relevant, log the result and set the flag to \"Yes\",\n",
        "            # which might indicate that a web search should be performed to supplement the retrieval.\n",
        "            print(\"*\" * 5, \" RATED DOCUMENT: NOT RELEVANT\", \"*\" * 5)\n",
        "            search = \"Yes\"\n",
        "            continue  # Skip adding this document\n",
        "\n",
        "    # Return the updated state with:\n",
        "    # - filtered_docs: Only the documents rated as relevant.\n",
        "    # - question: The original user question.\n",
        "    # - run_web_search: A flag indicating whether additional web search is needed.\n",
        "    return {\n",
        "        \"keys\": {\n",
        "            \"documents\": filtered_docs,\n",
        "            \"question\": question,\n",
        "            \"run_web_search\": search,\n",
        "        }\n",
        "    }\n"
      ],
      "metadata": {
        "id": "Gbtr0ThxaYr8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_query(state):\n",
        "    \"\"\"\n",
        "    Helper function for transforming the query to produce a better question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state containing at least a \"question\" and \"documents\" in its \"keys\".\n",
        "\n",
        "    Returns:\n",
        "        dict: A new state where the \"question\" key is updated with a re-phrased version of the original question.\n",
        "    \"\"\"\n",
        "\n",
        "    # Print a header message to indicate that the query transformation process has started.\n",
        "    print(\"*\" * 5, \"TRANSFORM QUERY\", \"*\" * 5)\n",
        "\n",
        "    # Extract the inner dictionary from the state that holds our relevant data.\n",
        "    state_dict = state[\"keys\"]\n",
        "\n",
        "    # Retrieve the current question from the state.\n",
        "    question = state_dict[\"question\"]\n",
        "\n",
        "    # Retrieve the documents; these are carried over unchanged.\n",
        "    documents = state_dict[\"documents\"]\n",
        "\n",
        "    # Create a prompt template designed to instruct the LLM to rephrase the original question.\n",
        "    # The template provides clear instructions to generate an improved, optimized question for retrieval.\n",
        "    prompt = PromptTemplate(\n",
        "        template=\"\"\"You are generating questions that is well optimized for retrieval. \\n\n",
        "        Look at the input and try to reason about the underlying semantic intent / meaning. \\n\n",
        "        Here is the initial question:\n",
        "        \\n --------- \\n\n",
        "        {question}\n",
        "        \\n --------- \\n\n",
        "        Formulate an improved question: \"\"\",\n",
        "        input_variables=[\"question\"],\n",
        "    )\n",
        "\n",
        "    # Initialize the language model (LLM) using ChatOpenAI with a specific GPT-4 preview model.\n",
        "    # Temperature is set to 0 for deterministic output, and streaming is enabled.\n",
        "    model = ChatOpenAI(temperature=0, model=\"gpt-4-0125-preview\", streaming=True)\n",
        "\n",
        "    # Build a chain that links the prompt, the language model, and a string output parser.\n",
        "    # The chain takes the input prompt, gets processed by the LLM, and then the output is parsed into a string.\n",
        "    chain = prompt | model | StrOutputParser()\n",
        "\n",
        "    # Invoke the chain with the current question to get a rephrased, better version of the question.\n",
        "    better_question = chain.invoke({\"question\": question})\n",
        "\n",
        "    # Return an updated state containing the original documents and the improved question.\n",
        "    return {\"keys\": {\"documents\": documents, \"question\": better_question}}\n"
      ],
      "metadata": {
        "id": "KlgkeVzNaYuF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def web_search(state):\n",
        "    \"\"\"\n",
        "    Helper function to do Web search based on the re-phrased question using Tavily API.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state containing at least \"question\" and \"documents\" in its \"keys\".\n",
        "\n",
        "    Returns:\n",
        "        dict: A new state where the \"documents\" key is updated with additional web search results appended.\n",
        "    \"\"\"\n",
        "\n",
        "    # Print a header message to signal the start of the web search process.\n",
        "    print(\"*\" * 5, \" WEB SEARCH \", \"*\" * 5)\n",
        "\n",
        "    # Extract the inner state dictionary from the overall state.\n",
        "    state_dict = state[\"keys\"]\n",
        "\n",
        "    # Retrieve the current question (which is assumed to be the re-phrased question).\n",
        "    question = state_dict[\"question\"]\n",
        "\n",
        "    # Retrieve the current list of documents.\n",
        "    documents = state_dict[\"documents\"]\n",
        "\n",
        "    # Initialize the web search tool. Here, TavilySearchResults is assumed to be a tool\n",
        "    # that interfaces with the Tavily API to perform web searches.\n",
        "    tool = TavilySearchResults()\n",
        "\n",
        "    # Invoke the tool with the question as the query.\n",
        "    # This should return a list of search results, where each result is expected to be a dictionary\n",
        "    # containing at least a \"content\" field.\n",
        "    docs = tool.invoke({\"query\": question})\n",
        "\n",
        "    # Extract the \"content\" from each search result and join them into a single string.\n",
        "    # The newline character (\"\\n\") separates the content from different search results.\n",
        "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
        "\n",
        "    # Wrap the concatenated web results in a Document object.\n",
        "    # This makes the web results compatible with the other document objects in the system.\n",
        "    web_results = Document(page_content=web_results)\n",
        "\n",
        "    # Append the newly created Document (containing the web search results) to the existing list of documents.\n",
        "    documents.append(web_results)\n",
        "\n",
        "    # Return the updated state with the appended web results.\n",
        "    # The question is preserved while the documents list now includes both the original documents and the new web search result.\n",
        "    return {\"keys\": {\"documents\": documents, \"question\": question}}\n"
      ],
      "metadata": {
        "id": "qItW-N8jaYwW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Edges"
      ],
      "metadata": {
        "id": "YmOyrR7xiEkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decide_to_generate(state):\n",
        "    \"\"\"\n",
        "    Helper function to determine whether to generate an answer or re-generate a question for web search.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current state of the agent, including all keys in its \"keys\" dictionary.\n",
        "\n",
        "    Returns:\n",
        "        str: The name of the next node to call, either \"transform_query\" or \"generate\".\n",
        "    \"\"\"\n",
        "\n",
        "    # Print a header message to signal that the decision-making process has started.\n",
        "    print(\"*\" * 5, \" DECIDE TO GENERATE \", \"*\" * 5)\n",
        "\n",
        "    # Extract the inner dictionary from the overall state, which holds the relevant keys.\n",
        "    state_dict = state[\"keys\"]\n",
        "\n",
        "    # Retrieve the current question from the state.\n",
        "    question = state_dict[\"question\"]\n",
        "\n",
        "    # Retrieve the filtered documents from the state. These documents have been previously processed.\n",
        "    filtered_documents = state_dict[\"documents\"]\n",
        "\n",
        "    # Retrieve the flag indicating whether a web search should be run.\n",
        "    # This flag (\"run_web_search\") was set in a previous step, based on document relevance.\n",
        "    search = state_dict[\"run_web_search\"]\n",
        "\n",
        "    # Decision-making logic:\n",
        "    # If the flag \"search\" is \"Yes\", it indicates that the documents were not sufficiently relevant.\n",
        "    # In that case, we should re-generate a new query (and subsequently perform a web search).\n",
        "    if search == \"Yes\":\n",
        "        # Log the decision.\n",
        "        print(\"*\" * 5, \" DECISION: TRANSFORM QUERY and RUN WEB SEARCH \", \"*\" * 5)\n",
        "        # Return the identifier for the next node that will transform the query.\n",
        "        return \"transform_query\"\n",
        "    else:\n",
        "        # If the flag is not \"Yes\", it means we have enough relevant documents.\n",
        "        # Log the decision.\n",
        "        print(\"*\" * 5, \" DECISION: GENERATE \", \"*\" * 5)\n",
        "        # Return the identifier for the node that will generate an answer using the relevant documents.\n",
        "        return \"generate\"\n"
      ],
      "metadata": {
        "id": "yql5N6TVaYyb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Graph\n",
        "\n",
        "The workflow defines the order in which nodes are executed:\n",
        "\n",
        "--> The workflow begins at the retrieve node.\n",
        "\n",
        "--> After retrieving documents, the next step is to grade their relevance.\n",
        "\n",
        "--> Here, decide_to_generate inspects the state (especially the run_web_search flag) and returns either \"transform_query\" or \"generate\". Depending on that result:\n",
        "\n",
        "1. If the decision is \"transform_query\", the workflow continues at the transform_query node.\n",
        "\n",
        "2. If it is \"generate\", it directly goes to the generate node.\n",
        "\n",
        "--> If the query was transformed, it then flows from transform_query to web_search to get additional results.\n",
        "\n",
        "--> After the web search, the process goes to generate where an answer is produced.\n",
        "Finally, once the answer is generated, the workflow reaches the end (marked by END).\n",
        "\n",
        "--> The compile() function finalizes the workflow. This step converts the graph into an executable application (or pipeline), which can then be run with an initial state. The compiled app manages the flow, ensuring that state is passed between nodes as defined by the edges and conditional logic.\n"
      ],
      "metadata": {
        "id": "7hUtu5oXiOZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Define the nodes\n",
        "workflow.add_node(\"retrieve\", retrieve)  # Retrieve documents from the source.\n",
        "workflow.add_node(\"grade_documents\", grade_documents)  # Grade the relevance of the retrieved documents.\n",
        "workflow.add_node(\"generate\", generate)  # Generate an answer using the documents.\n",
        "workflow.add_node(\"transform_query\", transform_query)  # Transform the query to optimize it for retrieval.\n",
        "workflow.add_node(\"web_search\", web_search)  # Perform a web search to supplement documents.\n",
        "\n",
        "\n",
        "# Build graph\n",
        "workflow.set_entry_point(\"retrieve\")\n",
        "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
        "\n",
        "# decide_to_generate inspects the state and returns either transform_query or generate depending on the result\n",
        "# If the decision is transform_query, the workflow continues at the transform_query node, if its generate, it directly goes to the generate node\n",
        "workflow.add_conditional_edges(\n",
        "    \"grade_documents\",\n",
        "    decide_to_generate,\n",
        "    {\n",
        "        \"transform_query\": \"transform_query\",\n",
        "        \"generate\": \"generate\",\n",
        "    },\n",
        ")\n",
        "workflow.add_edge(\"transform_query\", \"web_search\")\n",
        "workflow.add_edge(\"web_search\", \"generate\")\n",
        "workflow.add_edge(\"generate\", END)\n",
        "\n",
        "# Compile\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "f1VRZe9ciBY5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run\n",
        "# Set the initial query prompt.\n",
        "# query_prompt = \"How Transformers work?\"\n",
        "query_prompt = \"What is Machine Learning?\"\n",
        "\n",
        "# Build the initial input state as a dictionary.\n",
        "# The structure uses a \"keys\" key to store all state values, following our GraphState definition.\n",
        "inputs = {\"keys\": {\"question\": query_prompt}}\n",
        "\n",
        "# Stream through the workflow.\n",
        "# app.stream(inputs) executes the graph node-by-node, yielding the state at each step.\n",
        "for output in app.stream(inputs):\n",
        "    # For each output (which could contain multiple nodes in parallel or sequentially),\n",
        "    # iterate over its items. Each key represents a node, and its value holds the state.\n",
        "    for key, value in output.items():\n",
        "        # Print the full state (stored under the \"keys\" key) at the current node.\n",
        "        # This helps in understanding how the state evolves as it passes through each node.\n",
        "        pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
        "    # Print a separator between outputs from different nodes for clarity.\n",
        "    pprint.pprint(\"------------------------\")\n",
        "\n",
        "# After processing the pipeline, print the final generated answer.\n",
        "print(\"*\" * 5, \" Generated Answer \", \"*\" * 5)\n",
        "# The final state is held in 'value' from the last iteration of the loop.\n",
        "# We access the \"generation\" key to get the final answer produced by the generate node.\n",
        "pprint.pprint(value[\"keys\"][\"generation\"])\n"
      ],
      "metadata": {
        "id": "dVfeRH8ViBbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fae9d821-daca-4614-a203-93f1eb09f60a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****  RETRIEVE  *****\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-a30b8339471e>:27: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  documents = retriever.get_relevant_documents(question)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ 'documents': [ Document(metadata={'description': 'In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data', 'language': 'en', 'source': 'https://link.springer.com/article/10.1007/s42979-021-00592-x', 'title': 'Machine Learning: Algorithms, Real-World Applications and Research Directions | SN Computer Science\\n        '}, page_content='AbstractIn the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data, cybersecurity data, mobile data, business data, social media data, health data, etc. To intelligently analyze these data and develop the corresponding smart and automated\\xa0applications, the knowledge of artificial intelligence (AI), particularly, machine learning (ML) is the key. Various types of machine learning algorithms such as supervised, unsupervised, semi-supervised, and reinforcement learning exist in the area. Besides, the deep learning, which is part of a broader family of machine learning methods, can intelligently analyze the data on a large scale. In this paper, we present a comprehensive view on these machine learning algorithms that can be applied to enhance the intelligence and the capabilities of an application. Thus, this study’s key contribution is explaining the principles of different machine learning techniques and their applicability in various real-world application domains, such as cybersecurity\\xa0systems, smart cities, healthcare, e-commerce, agriculture, and many more. We also highlight the challenges and potential research directions based on our study. Overall, this'),\n",
            "                 Document(metadata={'description': 'In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data', 'language': 'en', 'source': 'https://link.springer.com/article/10.1007/s42979-021-00592-x', 'title': 'Machine Learning: Algorithms, Real-World Applications and Research Directions | SN Computer Science\\n        '}, page_content='“Machine Learning Tasks and Algorithms” can help to build context-aware adaptive and smart applications according to the preferences of the mobile phone users.'),\n",
            "                 Document(metadata={'description': 'In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data', 'language': 'en', 'source': 'https://link.springer.com/article/10.1007/s42979-021-00592-x', 'title': 'Machine Learning: Algorithms, Real-World Applications and Research Directions | SN Computer Science\\n        '}, page_content='Predictive analytics and intelligent decision-making: A major application field of machine learning is intelligent decision-making by data-driven predictive analytics [21, 70]. The basis of predictive analytics is capturing and exploiting relationships between explanatory variables and predicted variables from previous events to predict the unknown outcome [41]. For instance, identifying suspects or criminals after a crime has been committed, or detecting credit card fraud as it happens. Another application, where machine learning algorithms can assist retailers in better understanding consumer preferences and behavior, better manage inventory, avoiding out-of-stock situations, and optimizing logistics and warehousing in e-commerce. Various machine learning algorithms such as decision trees, support vector machines, artificial neural networks, etc. [106, 125] are commonly used in the area. Since accurate predictions provide insight into the unknown, they can improve the decisions of industries, businesses, and almost any organization, including government agencies, e-commerce, telecommunications, banking and financial services, healthcare, sales and marketing, transportation, social networking, and many others.'),\n",
            "                 Document(metadata={'description': 'In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data', 'language': 'en', 'source': 'https://link.springer.com/article/10.1007/s42979-021-00592-x', 'title': 'Machine Learning: Algorithms, Real-World Applications and Research Directions | SN Computer Science\\n        '}, page_content='1The worldwide popularity score of various types of ML algorithms (supervised, unsupervised, semi-supervised, and reinforcement) in a range of 0 (min) to 100 (max) over time where x-axis represents the timestamp information and y-axis represents the corresponding scoreFull size imageArtificial intelligence (AI), particularly, machine learning (ML) have grown rapidly in recent years in the context of data analysis and computing that typically allows the applications to function in an intelligent manner [95]. ML usually provides systems with the ability to learn and enhance from experience automatically without being specifically programmed and is generally referred to as the most popular latest technologies in the fourth industrial revolution (4IR or Industry 4.0) [103, 105]. “Industry 4.0” [114] is typically the ongoing automation of conventional manufacturing and industrial practices, including exploratory data processing, using new smart technologies such as machine learning automation. Thus, to intelligently analyze these data and to develop the corresponding real-world applications, machine learning algorithms is the key. The learning algorithms can be categorized into four major types, such as supervised, unsupervised, semi-supervised, and reinforcement learning in the area [75], discussed briefly')],\n",
            "  'question': 'What is Machine Learning?'}\n",
            "'------------------------'\n",
            "*****  DOCS RELEVANCE CHECK *****\n",
            "*****  RATED DOCUMENT: RELEVANT *****\n",
            "*****  RATED DOCUMENT: NOT RELEVANT *****\n",
            "*****  RATED DOCUMENT: NOT RELEVANT *****\n",
            "*****  RATED DOCUMENT: RELEVANT *****\n",
            "*****  DECIDE TO GENERATE  *****\n",
            "*****  DECISION: TRANSFORM QUERY and RUN WEB SEARCH  *****\n",
            "{ 'documents': [ Document(metadata={'description': 'In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data', 'language': 'en', 'source': 'https://link.springer.com/article/10.1007/s42979-021-00592-x', 'title': 'Machine Learning: Algorithms, Real-World Applications and Research Directions | SN Computer Science\\n        '}, page_content='AbstractIn the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data, cybersecurity data, mobile data, business data, social media data, health data, etc. To intelligently analyze these data and develop the corresponding smart and automated\\xa0applications, the knowledge of artificial intelligence (AI), particularly, machine learning (ML) is the key. Various types of machine learning algorithms such as supervised, unsupervised, semi-supervised, and reinforcement learning exist in the area. Besides, the deep learning, which is part of a broader family of machine learning methods, can intelligently analyze the data on a large scale. In this paper, we present a comprehensive view on these machine learning algorithms that can be applied to enhance the intelligence and the capabilities of an application. Thus, this study’s key contribution is explaining the principles of different machine learning techniques and their applicability in various real-world application domains, such as cybersecurity\\xa0systems, smart cities, healthcare, e-commerce, agriculture, and many more. We also highlight the challenges and potential research directions based on our study. Overall, this'),\n",
            "                 Document(metadata={'description': 'In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data', 'language': 'en', 'source': 'https://link.springer.com/article/10.1007/s42979-021-00592-x', 'title': 'Machine Learning: Algorithms, Real-World Applications and Research Directions | SN Computer Science\\n        '}, page_content='1The worldwide popularity score of various types of ML algorithms (supervised, unsupervised, semi-supervised, and reinforcement) in a range of 0 (min) to 100 (max) over time where x-axis represents the timestamp information and y-axis represents the corresponding scoreFull size imageArtificial intelligence (AI), particularly, machine learning (ML) have grown rapidly in recent years in the context of data analysis and computing that typically allows the applications to function in an intelligent manner [95]. ML usually provides systems with the ability to learn and enhance from experience automatically without being specifically programmed and is generally referred to as the most popular latest technologies in the fourth industrial revolution (4IR or Industry 4.0) [103, 105]. “Industry 4.0” [114] is typically the ongoing automation of conventional manufacturing and industrial practices, including exploratory data processing, using new smart technologies such as machine learning automation. Thus, to intelligently analyze these data and to develop the corresponding real-world applications, machine learning algorithms is the key. The learning algorithms can be categorized into four major types, such as supervised, unsupervised, semi-supervised, and reinforcement learning in the area [75], discussed briefly')],\n",
            "  'question': 'What is Machine Learning?',\n",
            "  'run_web_search': 'Yes'}\n",
            "'------------------------'\n",
            "***** TRANSFORM QUERY *****\n",
            "{ 'documents': [ Document(metadata={'description': 'In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data', 'language': 'en', 'source': 'https://link.springer.com/article/10.1007/s42979-021-00592-x', 'title': 'Machine Learning: Algorithms, Real-World Applications and Research Directions | SN Computer Science\\n        '}, page_content='AbstractIn the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data, cybersecurity data, mobile data, business data, social media data, health data, etc. To intelligently analyze these data and develop the corresponding smart and automated\\xa0applications, the knowledge of artificial intelligence (AI), particularly, machine learning (ML) is the key. Various types of machine learning algorithms such as supervised, unsupervised, semi-supervised, and reinforcement learning exist in the area. Besides, the deep learning, which is part of a broader family of machine learning methods, can intelligently analyze the data on a large scale. In this paper, we present a comprehensive view on these machine learning algorithms that can be applied to enhance the intelligence and the capabilities of an application. Thus, this study’s key contribution is explaining the principles of different machine learning techniques and their applicability in various real-world application domains, such as cybersecurity\\xa0systems, smart cities, healthcare, e-commerce, agriculture, and many more. We also highlight the challenges and potential research directions based on our study. Overall, this'),\n",
            "                 Document(metadata={'description': 'In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data', 'language': 'en', 'source': 'https://link.springer.com/article/10.1007/s42979-021-00592-x', 'title': 'Machine Learning: Algorithms, Real-World Applications and Research Directions | SN Computer Science\\n        '}, page_content='1The worldwide popularity score of various types of ML algorithms (supervised, unsupervised, semi-supervised, and reinforcement) in a range of 0 (min) to 100 (max) over time where x-axis represents the timestamp information and y-axis represents the corresponding scoreFull size imageArtificial intelligence (AI), particularly, machine learning (ML) have grown rapidly in recent years in the context of data analysis and computing that typically allows the applications to function in an intelligent manner [95]. ML usually provides systems with the ability to learn and enhance from experience automatically without being specifically programmed and is generally referred to as the most popular latest technologies in the fourth industrial revolution (4IR or Industry 4.0) [103, 105]. “Industry 4.0” [114] is typically the ongoing automation of conventional manufacturing and industrial practices, including exploratory data processing, using new smart technologies such as machine learning automation. Thus, to intelligently analyze these data and to develop the corresponding real-world applications, machine learning algorithms is the key. The learning algorithms can be categorized into four major types, such as supervised, unsupervised, semi-supervised, and reinforcement learning in the area [75], discussed briefly')],\n",
            "  'question': 'What are the basic principles and applications of Machine '\n",
            "              'Learning?'}\n",
            "'------------------------'\n",
            "*****  WEB SEARCH  *****\n",
            "{ 'documents': [ Document(metadata={'description': 'In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data', 'language': 'en', 'source': 'https://link.springer.com/article/10.1007/s42979-021-00592-x', 'title': 'Machine Learning: Algorithms, Real-World Applications and Research Directions | SN Computer Science\\n        '}, page_content='AbstractIn the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data, cybersecurity data, mobile data, business data, social media data, health data, etc. To intelligently analyze these data and develop the corresponding smart and automated\\xa0applications, the knowledge of artificial intelligence (AI), particularly, machine learning (ML) is the key. Various types of machine learning algorithms such as supervised, unsupervised, semi-supervised, and reinforcement learning exist in the area. Besides, the deep learning, which is part of a broader family of machine learning methods, can intelligently analyze the data on a large scale. In this paper, we present a comprehensive view on these machine learning algorithms that can be applied to enhance the intelligence and the capabilities of an application. Thus, this study’s key contribution is explaining the principles of different machine learning techniques and their applicability in various real-world application domains, such as cybersecurity\\xa0systems, smart cities, healthcare, e-commerce, agriculture, and many more. We also highlight the challenges and potential research directions based on our study. Overall, this'),\n",
            "                 Document(metadata={'description': 'In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data', 'language': 'en', 'source': 'https://link.springer.com/article/10.1007/s42979-021-00592-x', 'title': 'Machine Learning: Algorithms, Real-World Applications and Research Directions | SN Computer Science\\n        '}, page_content='1The worldwide popularity score of various types of ML algorithms (supervised, unsupervised, semi-supervised, and reinforcement) in a range of 0 (min) to 100 (max) over time where x-axis represents the timestamp information and y-axis represents the corresponding scoreFull size imageArtificial intelligence (AI), particularly, machine learning (ML) have grown rapidly in recent years in the context of data analysis and computing that typically allows the applications to function in an intelligent manner [95]. ML usually provides systems with the ability to learn and enhance from experience automatically without being specifically programmed and is generally referred to as the most popular latest technologies in the fourth industrial revolution (4IR or Industry 4.0) [103, 105]. “Industry 4.0” [114] is typically the ongoing automation of conventional manufacturing and industrial practices, including exploratory data processing, using new smart technologies such as machine learning automation. Thus, to intelligently analyze these data and to develop the corresponding real-world applications, machine learning algorithms is the key. The learning algorithms can be categorized into four major types, such as supervised, unsupervised, semi-supervised, and reinforcement learning in the area [75], discussed briefly'),\n",
            "                 Document(metadata={}, page_content='ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine.[3][4] The application of ML to business problems is known as predictive analytics.\\nStatistics and mathematical optimization (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning.[6][7] [...] Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.[1] Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.[2] [...] Applications[edit]\\nThere are many applications for machine learning, including:\\nAgriculture\\nAnatomy\\nAdaptive website\\nAffective computing\\nAstronomy\\nAutomated decision-making\\nBanking\\nBehaviorism\\nBioinformatics\\nBrain–machine interfaces\\nCheminformatics\\nCitizen Science\\nClimate Science\\nComputer networks\\nComputer vision\\nCredit-card fraud detection\\nData quality\\nDNA sequence classification\\nEconomics\\nFinancial market analysis[97]\\nGeneral game playing\\nHandwriting recognition\\nHealthcare\\nIn this article, we will delve into the fundamental principles of machine learning and its practical applications in the real world.\\nThe principles of machine learning (ML) focus on building models that can learn from data and make predictions or decisions without explicit programming.\\n*Machine learning (ML) allows computers to learn and make decisions without being explicitly programmed. It involves feeding data into algorithms to identify patterns and make predictions on new data.* Machine learning is used in various applications, including image and speech recognition, natural language processing, and recommender systems. [...] Introduction to Machine Learning: What Is and Its Applications Machine learning (ML) allows computers to learn and make decisions without being explicitly programmed. It involves feeding data into algorithms to identify patterns and make predictions on new data. Machine learning is used in various applications, including image and speech recognition, natural la 6 min read [...] *Data Input:* Machines require data (e.g., text, images, numbers) to analyze.\\n*Algorithms:* Algorithms process the data, finding patterns or relationships.\\n*Model Training:* Machines learn by adjusting their parameters based on the input data using mathematical models.\\n*Feedback Loop:* The machine compares predictions to actual outcomes and corrects errors (via optimization methods like gradient descent).\\n– (2,10), (5,19), and (9,31) The algorithm computes the relationship between input and output to be: o=3*i+4 We then give it input 7 and ask it to predict the output. It can automatically determine the output as 25. While this is a basic understanding, machine learning focuses on the principle that computer systems can mathematically link all complex data points as long as they have sufficient data and computing power to process. Therefore, the accuracy of the output is directly co-relational [...] The central idea behind machine learning is an existing mathematical relationship between any input and output data combination. The machine learning model does not know this relationship in advance but can guess if sufficient examples of input-output data sets are given. This means every machine learning algorithm is built around a modifiable math function. The underlying principle can be understood like this: We ‘train’ the algorithm by giving it the following input/output (i,o) combinations [...] Machine learning is a type of artificial intelligence that performs data analysis tasks without explicit instructions. Machine learning technology can process large quantities of historical data, identify patterns, and predict new relationships between previously unknown data. You can perform classification and prediction tasks on documents, images, numbers, and other data types.')],\n",
            "  'question': 'What are the basic principles and applications of Machine '\n",
            "              'Learning?'}\n",
            "'------------------------'\n",
            "*****  GENERATE  *****\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:277: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ 'documents': [ Document(metadata={'description': 'In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data', 'language': 'en', 'source': 'https://link.springer.com/article/10.1007/s42979-021-00592-x', 'title': 'Machine Learning: Algorithms, Real-World Applications and Research Directions | SN Computer Science\\n        '}, page_content='AbstractIn the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data, cybersecurity data, mobile data, business data, social media data, health data, etc. To intelligently analyze these data and develop the corresponding smart and automated\\xa0applications, the knowledge of artificial intelligence (AI), particularly, machine learning (ML) is the key. Various types of machine learning algorithms such as supervised, unsupervised, semi-supervised, and reinforcement learning exist in the area. Besides, the deep learning, which is part of a broader family of machine learning methods, can intelligently analyze the data on a large scale. In this paper, we present a comprehensive view on these machine learning algorithms that can be applied to enhance the intelligence and the capabilities of an application. Thus, this study’s key contribution is explaining the principles of different machine learning techniques and their applicability in various real-world application domains, such as cybersecurity\\xa0systems, smart cities, healthcare, e-commerce, agriculture, and many more. We also highlight the challenges and potential research directions based on our study. Overall, this'),\n",
            "                 Document(metadata={'description': 'In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data', 'language': 'en', 'source': 'https://link.springer.com/article/10.1007/s42979-021-00592-x', 'title': 'Machine Learning: Algorithms, Real-World Applications and Research Directions | SN Computer Science\\n        '}, page_content='1The worldwide popularity score of various types of ML algorithms (supervised, unsupervised, semi-supervised, and reinforcement) in a range of 0 (min) to 100 (max) over time where x-axis represents the timestamp information and y-axis represents the corresponding scoreFull size imageArtificial intelligence (AI), particularly, machine learning (ML) have grown rapidly in recent years in the context of data analysis and computing that typically allows the applications to function in an intelligent manner [95]. ML usually provides systems with the ability to learn and enhance from experience automatically without being specifically programmed and is generally referred to as the most popular latest technologies in the fourth industrial revolution (4IR or Industry 4.0) [103, 105]. “Industry 4.0” [114] is typically the ongoing automation of conventional manufacturing and industrial practices, including exploratory data processing, using new smart technologies such as machine learning automation. Thus, to intelligently analyze these data and to develop the corresponding real-world applications, machine learning algorithms is the key. The learning algorithms can be categorized into four major types, such as supervised, unsupervised, semi-supervised, and reinforcement learning in the area [75], discussed briefly'),\n",
            "                 Document(metadata={}, page_content='ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine.[3][4] The application of ML to business problems is known as predictive analytics.\\nStatistics and mathematical optimization (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning.[6][7] [...] Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.[1] Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.[2] [...] Applications[edit]\\nThere are many applications for machine learning, including:\\nAgriculture\\nAnatomy\\nAdaptive website\\nAffective computing\\nAstronomy\\nAutomated decision-making\\nBanking\\nBehaviorism\\nBioinformatics\\nBrain–machine interfaces\\nCheminformatics\\nCitizen Science\\nClimate Science\\nComputer networks\\nComputer vision\\nCredit-card fraud detection\\nData quality\\nDNA sequence classification\\nEconomics\\nFinancial market analysis[97]\\nGeneral game playing\\nHandwriting recognition\\nHealthcare\\nIn this article, we will delve into the fundamental principles of machine learning and its practical applications in the real world.\\nThe principles of machine learning (ML) focus on building models that can learn from data and make predictions or decisions without explicit programming.\\n*Machine learning (ML) allows computers to learn and make decisions without being explicitly programmed. It involves feeding data into algorithms to identify patterns and make predictions on new data.* Machine learning is used in various applications, including image and speech recognition, natural language processing, and recommender systems. [...] Introduction to Machine Learning: What Is and Its Applications Machine learning (ML) allows computers to learn and make decisions without being explicitly programmed. It involves feeding data into algorithms to identify patterns and make predictions on new data. Machine learning is used in various applications, including image and speech recognition, natural la 6 min read [...] *Data Input:* Machines require data (e.g., text, images, numbers) to analyze.\\n*Algorithms:* Algorithms process the data, finding patterns or relationships.\\n*Model Training:* Machines learn by adjusting their parameters based on the input data using mathematical models.\\n*Feedback Loop:* The machine compares predictions to actual outcomes and corrects errors (via optimization methods like gradient descent).\\n– (2,10), (5,19), and (9,31) The algorithm computes the relationship between input and output to be: o=3*i+4 We then give it input 7 and ask it to predict the output. It can automatically determine the output as 25. While this is a basic understanding, machine learning focuses on the principle that computer systems can mathematically link all complex data points as long as they have sufficient data and computing power to process. Therefore, the accuracy of the output is directly co-relational [...] The central idea behind machine learning is an existing mathematical relationship between any input and output data combination. The machine learning model does not know this relationship in advance but can guess if sufficient examples of input-output data sets are given. This means every machine learning algorithm is built around a modifiable math function. The underlying principle can be understood like this: We ‘train’ the algorithm by giving it the following input/output (i,o) combinations [...] Machine learning is a type of artificial intelligence that performs data analysis tasks without explicit instructions. Machine learning technology can process large quantities of historical data, identify patterns, and predict new relationships between previously unknown data. You can perform classification and prediction tasks on documents, images, numbers, and other data types.')],\n",
            "  'generation': 'The basic principles of machine learning involve building '\n",
            "                'models that learn from data to make predictions or decisions '\n",
            "                'without explicit programming, utilizing algorithms to '\n",
            "                'identify patterns. Applications of machine learning span '\n",
            "                'various fields, including healthcare, finance, agriculture, '\n",
            "                'and natural language processing, enabling tasks like image '\n",
            "                'recognition and predictive analytics. Overall, machine '\n",
            "                'learning enhances the intelligence and capabilities of '\n",
            "                'applications in the context of the Fourth Industrial '\n",
            "                'Revolution.',\n",
            "  'question': 'What are the basic principles and applications of Machine '\n",
            "              'Learning?'}\n",
            "'------------------------'\n",
            "*****  Generated Answer  *****\n",
            "('The basic principles of machine learning involve building models that learn '\n",
            " 'from data to make predictions or decisions without explicit programming, '\n",
            " 'utilizing algorithms to identify patterns. Applications of machine learning '\n",
            " 'span various fields, including healthcare, finance, agriculture, and natural '\n",
            " 'language processing, enabling tasks like image recognition and predictive '\n",
            " 'analytics. Overall, machine learning enhances the intelligence and '\n",
            " 'capabilities of applications in the context of the Fourth Industrial '\n",
            " 'Revolution.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input state with a question that might not have related context\n",
        "inputs = {\n",
        "    \"keys\": {\n",
        "        \"question\": \"Explain a framework called React.Js?\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Run the workflow using the stream() method.\n",
        "# The workflow processes the input through all defined nodes, yielding the state at each step.\n",
        "for output in app.stream(inputs):\n",
        "    # For each output (which represents one or more nodes in the pipeline),\n",
        "    # iterate over the items to inspect the state of each node.\n",
        "    for key, value in output.items():\n",
        "        # Print the full state stored under the \"keys\" dictionary.\n",
        "        # This allows you to see how the state evolves through each node (e.g., retrieval, grading, etc.).\n",
        "        pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
        "    # Print a separator line to distinguish the output of different nodes.\n",
        "    pprint.pprint(\"------------------------\")\n",
        "\n",
        "# After streaming through the workflow, the final state is obtained.\n",
        "# Print the final generated answer.\n",
        "print(\"*\" * 5, \" Generated Answer \", \"*\" * 5)\n",
        "pprint.pprint(value[\"keys\"][\"generation\"])\n"
      ],
      "metadata": {
        "id": "JhzlGdmziBeF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d6ab278-e8e8-438e-ab36-dac48a68d998"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****  RETRIEVE  *****\n",
            "{ 'documents': [ Document(metadata={'description': 'In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data', 'language': 'en', 'source': 'https://link.springer.com/article/10.1007/s42979-021-00592-x', 'title': 'Machine Learning: Algorithms, Real-World Applications and Research Directions | SN Computer Science\\n        '}, page_content='“Machine Learning Tasks and Algorithms” can help to build context-aware adaptive and smart applications according to the preferences of the mobile phone users.'),\n",
            "                 Document(metadata={'description': 'In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data', 'language': 'en', 'source': 'https://link.springer.com/article/10.1007/s42979-021-00592-x', 'title': 'Machine Learning: Algorithms, Real-World Applications and Research Directions | SN Computer Science\\n        '}, page_content='(4)'),\n",
            "                 Document(metadata={'description': 'In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data', 'language': 'en', 'source': 'https://link.springer.com/article/10.1007/s42979-021-00592-x', 'title': 'Machine Learning: Algorithms, Real-World Applications and Research Directions | SN Computer Science\\n        '}, page_content='(8)'),\n",
            "                 Document(metadata={'description': 'In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data', 'language': 'en', 'source': 'https://link.springer.com/article/10.1007/s42979-021-00592-x', 'title': 'Machine Learning: Algorithms, Real-World Applications and Research Directions | SN Computer Science\\n        '}, page_content='(CNN, or ConvNet), Long Short-Term Memory Recurrent Neural Network (LSTM-RNN) [96]. In the following, we discuss various types of deep learning methods that can be used to build effective data-driven models for various purposes.Fig. 10A structure of an artificial neural network modeling with multiple processing layersFull size image')],\n",
            "  'question': 'Explain a framework called React.Js?'}\n",
            "'------------------------'\n",
            "*****  DOCS RELEVANCE CHECK *****\n",
            "*****  RATED DOCUMENT: NOT RELEVANT *****\n",
            "*****  RATED DOCUMENT: NOT RELEVANT *****\n",
            "*****  RATED DOCUMENT: NOT RELEVANT *****\n",
            "*****  RATED DOCUMENT: NOT RELEVANT *****\n",
            "*****  DECIDE TO GENERATE  *****\n",
            "*****  DECISION: TRANSFORM QUERY and RUN WEB SEARCH  *****\n",
            "{ 'documents': [],\n",
            "  'question': 'Explain a framework called React.Js?',\n",
            "  'run_web_search': 'Yes'}\n",
            "'------------------------'\n",
            "***** TRANSFORM QUERY *****\n",
            "{ 'documents': [],\n",
            "  'question': 'What is the React.js framework and how does it work?'}\n",
            "'------------------------'\n",
            "*****  WEB SEARCH  *****\n",
            "{ 'documents': [ Document(metadata={}, page_content=\"ReactJS is a popular JavaScript library developed by Facebook for building dynamic and interactive user interfaces, particularly for\\nReact is a JavaScript library used for building user interfaces, especially for single-page applications where the user interacts with the\\nReact is a framework that employs Webpack to automatically compile React, JSX, and ES6 code while handling CSS file prefixes. React is a JavaScript-based UI development library. Although React is a library rather than a language, it is widely used in web development. The library first appeared in May 2013 and is now one of the most commonly used frontend libraries for web development. [...] ReactJS is a free, element front-end toolkit that is exclusively in charge of the software's layered architecture.\\n\\n### 4\\\\. What is the difference between React and React JS?\\n\\nAlthough Reactjs is essentially a Software framework and React Native is the whole framework, the two work in harmony because the former forms the core of the latter. React Native is perfect for giving your mobile apps a native feel, just as Reactjs is ideal for building apps with higher efficacy and complications . [...] React.js builds a customized virtual DOM. Because the JavaScript virtual DOM is quicker than the conventional DOM, this will enhance the performance of apps.\\xa0\\nReactJS makes an amazing UI possible.\\xa0\\nSearch - engine friendly ReactJS.\\xa0\\nModules and valid data make larger apps easier to manage by increasing readability.\\xa0\\nReact integrates various architectures.\\xa0\\nReact makes the entire scripting environment process simpler.\\xa0\\nIt makes advanced maintenance easier and boosts output.\\nHow does React work?\\nReact operates by creating an in-memory virtual DOM rather than directly manipulating the browser’s DOM. It performs necessary manipulations within this virtual representation before applying changes to the actual browser DOM.\\nHow does React work\\n*Here’s how the process works*\\n*1. Actual DOM and Virtual DOM* [...] React Introduction ReactJS is a component-based JavaScript library used to build dynamic and interactive user interfaces. It simplifies the creation of single-page applications (SPAs) with a focus on performance and maintainability. It is developed and maintained by Facebook.Uses a virtual DOM for faster updates.Suppo 6 min read [...] ▲\\nOpen In App\\nNext Article: React Environment Setup \\nReact Introduction\\nLast Updated : 28 Jan, 2025\\nSummarize\\nComments\\nImprove\\nSuggest changes\\n264 Likes\\nLike\\nShare\\nReport\\n Follow\\nReactJS is a *component-based* JavaScript library used to build dynamic and interactive user interfaces. It simplifies the creation of single-page applications (SPAs) with a focus on performance and maintainability.\\nReact is a JavaScript library that was created by Facebook in 2011 and then open-sourced in 2013. React made headlines as an efficient, flexible and declarative JavaScript library for building interactive websites. It’s really good at developing web apps that require constant data changes on their user interfaces. Its most successful apps are Instagram and Facebook, which are notable for being responsive and fast. [...] A good popularity measurement is community activity on that topic. And we see that people are most willing to ask questions and answer them on React topics, according to Stack Overflow. Other libraries and frameworks aren’t even close.\\n\\nIs React a Framework? Answered\\n\\nReact is a JavaScript library that’s used for building reactive websites. While it’s not a framework, React does have a dedicated framework called Create React App that can be used to build web applications. [...] To compete with frameworks, React has a dedicated framework called Create React App (CRA). It includes file structuring and other tools so that React could be used as a framework. It’s the best way to start building a new single-page application in React.\\n\\nCRA creates a development environment to build a React-based web app and optimizes your app for production right out of the box.\")],\n",
            "  'question': 'What is the React.js framework and how does it work?'}\n",
            "'------------------------'\n",
            "*****  GENERATE  *****\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:277: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ 'documents': [ Document(metadata={}, page_content=\"ReactJS is a popular JavaScript library developed by Facebook for building dynamic and interactive user interfaces, particularly for\\nReact is a JavaScript library used for building user interfaces, especially for single-page applications where the user interacts with the\\nReact is a framework that employs Webpack to automatically compile React, JSX, and ES6 code while handling CSS file prefixes. React is a JavaScript-based UI development library. Although React is a library rather than a language, it is widely used in web development. The library first appeared in May 2013 and is now one of the most commonly used frontend libraries for web development. [...] ReactJS is a free, element front-end toolkit that is exclusively in charge of the software's layered architecture.\\n\\n### 4\\\\. What is the difference between React and React JS?\\n\\nAlthough Reactjs is essentially a Software framework and React Native is the whole framework, the two work in harmony because the former forms the core of the latter. React Native is perfect for giving your mobile apps a native feel, just as Reactjs is ideal for building apps with higher efficacy and complications . [...] React.js builds a customized virtual DOM. Because the JavaScript virtual DOM is quicker than the conventional DOM, this will enhance the performance of apps.\\xa0\\nReactJS makes an amazing UI possible.\\xa0\\nSearch - engine friendly ReactJS.\\xa0\\nModules and valid data make larger apps easier to manage by increasing readability.\\xa0\\nReact integrates various architectures.\\xa0\\nReact makes the entire scripting environment process simpler.\\xa0\\nIt makes advanced maintenance easier and boosts output.\\nHow does React work?\\nReact operates by creating an in-memory virtual DOM rather than directly manipulating the browser’s DOM. It performs necessary manipulations within this virtual representation before applying changes to the actual browser DOM.\\nHow does React work\\n*Here’s how the process works*\\n*1. Actual DOM and Virtual DOM* [...] React Introduction ReactJS is a component-based JavaScript library used to build dynamic and interactive user interfaces. It simplifies the creation of single-page applications (SPAs) with a focus on performance and maintainability. It is developed and maintained by Facebook.Uses a virtual DOM for faster updates.Suppo 6 min read [...] ▲\\nOpen In App\\nNext Article: React Environment Setup \\nReact Introduction\\nLast Updated : 28 Jan, 2025\\nSummarize\\nComments\\nImprove\\nSuggest changes\\n264 Likes\\nLike\\nShare\\nReport\\n Follow\\nReactJS is a *component-based* JavaScript library used to build dynamic and interactive user interfaces. It simplifies the creation of single-page applications (SPAs) with a focus on performance and maintainability.\\nReact is a JavaScript library that was created by Facebook in 2011 and then open-sourced in 2013. React made headlines as an efficient, flexible and declarative JavaScript library for building interactive websites. It’s really good at developing web apps that require constant data changes on their user interfaces. Its most successful apps are Instagram and Facebook, which are notable for being responsive and fast. [...] A good popularity measurement is community activity on that topic. And we see that people are most willing to ask questions and answer them on React topics, according to Stack Overflow. Other libraries and frameworks aren’t even close.\\n\\nIs React a Framework? Answered\\n\\nReact is a JavaScript library that’s used for building reactive websites. While it’s not a framework, React does have a dedicated framework called Create React App that can be used to build web applications. [...] To compete with frameworks, React has a dedicated framework called Create React App (CRA). It includes file structuring and other tools so that React could be used as a framework. It’s the best way to start building a new single-page application in React.\\n\\nCRA creates a development environment to build a React-based web app and optimizes your app for production right out of the box.\")],\n",
            "  'generation': 'React.js is a popular JavaScript library developed by '\n",
            "                'Facebook for building dynamic and interactive user '\n",
            "                'interfaces, particularly for single-page applications. It '\n",
            "                'works by creating an in-memory virtual DOM, allowing for '\n",
            "                'efficient updates by manipulating this virtual representation '\n",
            "                'before applying changes to the actual browser DOM. This '\n",
            "                'approach enhances performance and maintainability in web '\n",
            "                'applications.',\n",
            "  'question': 'What is the React.js framework and how does it work?'}\n",
            "'------------------------'\n",
            "*****  Generated Answer  *****\n",
            "('React.js is a popular JavaScript library developed by Facebook for building '\n",
            " 'dynamic and interactive user interfaces, particularly for single-page '\n",
            " 'applications. It works by creating an in-memory virtual DOM, allowing for '\n",
            " 'efficient updates by manipulating this virtual representation before '\n",
            " 'applying changes to the actual browser DOM. This approach enhances '\n",
            " 'performance and maintainability in web applications.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p6plNuGEiBgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DaFMbBYrlNcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gcodYuC2iBoa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}